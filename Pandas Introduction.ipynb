{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "featured-bidder",
   "metadata": {},
   "source": [
    "# Pandas: Your Data's Best Friend\n",
    "Two of the most useful things that Python can do for you as a reasercher is allow you to wrangle and visualize data quickly and responsively. We will be using the `pandas` module for data management. If you are interested, there are many tutorials out there which compliment what we are going to teach quite well, for example this Pandas tutorial on [Kaggle](https://www.kaggle.com/learn/pandas).\n",
    "\n",
    "Let's start by importing these modules. We will use the shorthand `pd` for Pandas as a common abbreviation and  will make our lives just a little bit easier. We're also going to import numpy (as `np`) directly as we will need to access it later:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "secure-found",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abroad-polymer",
   "metadata": {},
   "source": [
    "This workbook is organized to introduce various features, elements, techniques, and processes available to us using Pandas and Altair in research. We are going to walk through some of these steps using data that we have created, but mostly we are going to use and existing dataset to get used to working with real data that is often messy.\n",
    "\n",
    "## VIA Rail Reliability\n",
    "Our goal (case study, example) is to perform some analysis of the reliability of VIA Rail in 2019, particularly along a single corridor (the Kitchener corridor).\n",
    "\n",
    "The data we will be working with consists of real and scheduled arrival and departure times of trains on portions of the VIA rail network in Canada. This data was collected from VIA's website, which reports these times as part of their customer service process. I have been collecting and storing this data for analysis, and we will use a year's worth of data for this example. \n",
    "\n",
    "For reference, here's a map of the railway system, complete with station names:\n",
    "<img src=\"via_corridor.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "absent-birmingham",
   "metadata": {},
   "source": [
    "## Pandas Data Frames\n",
    "The meat and potatoes of data management in Pandas happens through the `DataFrame` object, and it's 1-dimensional cousin the `Series`. Data frames can be thought of just like tables in a database, or a single spreadsheet in an excel workbook. Series objects are like lists, and represent a single column in a data frame. There are many ways to create a data frame, here are common ones:\n",
    "  * Read in data from a CSV file\n",
    "  * Read in data from a Database\n",
    "  * Create one in code\n",
    "  \n",
    "By far the most common approach is to read in a CSV file. Depending on the file size and the types of data, Pandas will automatically try to guess what types of data are in each column (strings, integers, floats), but you can tell it explicitly to make things run faster. We can view the size of the frame using the `shape` attribute, view the column names using the `columns` attribute, and the top rows of the data frame using the `head()` function.\n",
    "\n",
    "### Creating Data Frames from Scratch\n",
    "While not a common thing, sometimes it can be useful to create a data frame from scractch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minor-century",
   "metadata": {},
   "outputs": [],
   "source": [
    "votes = pd.DataFrame({'Motion': ['G-25', 'C-50', 'C-59'], 'For':[21, 15, 22], 'Against': [23, 29, 22]})\n",
    "votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "athletic-belly",
   "metadata": {},
   "outputs": [],
   "source": [
    "via = pd.read_csv('data/via_2019_all.csv')\n",
    "display(via.shape)\n",
    "display(via.columns)\n",
    "via.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extreme-subscriber",
   "metadata": {},
   "source": [
    "### Slicing and Selecting\n",
    "You can view individual slices of the data by row or column. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "greatest-samuel",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(via.iloc[250])\n",
    "display(via.train.unique())\n",
    "via[['train', 'prettyname']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "appointed-coupon",
   "metadata": {},
   "source": [
    "### Conditional Selection\n",
    "A common thing you'll want to do is to filter the data you have based on a set of criteria. This can be done by passing a set of filtering arguments, treating the Data Frame a little like a dictionary.\n",
    "\n",
    "For multiple criteria Pandas uses Python's *bitwise operators*, which are `&` for AND and `|` for OR. If your filtering criteria are complex, don't forget about DeMorgan's law!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amino-african",
   "metadata": {},
   "outputs": [],
   "source": [
    "via[(via.train >= 80) & (via.train < 90)].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "whole-outdoors",
   "metadata": {},
   "source": [
    "### Working with Subsets\n",
    "You can assign subsets to new variables, but **be careful**. These subsets *sometimes* act as direct copies, sometimes they are simply selections on the larger frame. When you are making changes to the data, remember that if you want a true copy, you can use the `copy()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sitting-methodology",
   "metadata": {},
   "outputs": [],
   "source": [
    "kitchener = via[(via.train >= 85) & (via.train < 90)].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "attempted-cooper",
   "metadata": {},
   "source": [
    "### Grouping Data\n",
    "It's often useful to aggregate or group data together. We can do this using Pandas' `groupby` function. There are many different ways to do this, based on your application or how you use the output, but here's my approach:\n",
    "  1. Slice your data frame so you have only the columns for grouping, and the columns for aggregating (at least one)\n",
    "  2. Group on the groupby columns, use `as_index=False` to keep your dataframe flat.\n",
    "  3. Provide an aggregation function (simple or complex) after your `groupby` call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "competent-circular",
   "metadata": {},
   "outputs": [],
   "source": [
    "kitchener[['train', 'prettyname', 'schedArr']].groupby(['train', 'prettyname'], as_index=False).count().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "announced-analysis",
   "metadata": {},
   "source": [
    "### Sorting Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cultural-nation",
   "metadata": {},
   "outputs": [],
   "source": [
    "kitchener.sort_values(by='prettyname', ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "northern-usage",
   "metadata": {},
   "source": [
    "### Data Types\n",
    "Much like with Python in general, we have to pay attention to data types in Pandas, and make sure that the data type that Pandas associates with a given column matches what we need it do be. Let's check the data types for our data set (note, the `object` type is what Pandas uses for string columns):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "specific-mainstream",
   "metadata": {},
   "outputs": [],
   "source": [
    "kitchener.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "approximate-desktop",
   "metadata": {},
   "source": [
    "What we'd *really* like is for the time columns to be treated as time, so we can do operations with them without too much fuss. Here's how we can convert:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lesser-packaging",
   "metadata": {},
   "outputs": [],
   "source": [
    "kitchener['schedArr'] = pd.to_datetime(kitchener.schedArr)\n",
    "kitchener['realArr'] = pd.to_datetime(kitchener.realArr)\n",
    "kitchener['schedDep'] = pd.to_datetime(kitchener.schedDep)\n",
    "kitchener['realDep'] = pd.to_datetime(kitchener.realDep)\n",
    "kitchener.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "demonstrated-health",
   "metadata": {},
   "source": [
    "### Making New Columns\n",
    "We can create new columns in the data based on other columns very easily:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "weekly-fortune",
   "metadata": {},
   "outputs": [],
   "source": [
    "kitchener['arrDelta'] = kitchener['realArr'] - kitchener['schedArr']\n",
    "kitchener['depDelta'] = kitchener['realDep'] - kitchener['schedDep']\n",
    "display(kitchener.dtypes)\n",
    "kitchener['arrDelta'] = kitchener['arrDelta'].dt.total_seconds()/60.0\n",
    "kitchener['depDelta'] = kitchener['depDelta'].dt.total_seconds()/60.0\n",
    "kitchener.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "certain-thought",
   "metadata": {},
   "source": [
    "### Summaries\n",
    "The `describe()` function can help us get some insights into our data very quickly, and let us know if there are any issues. We will use this summary function to determine some data integrity issues and to correct them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "important-church",
   "metadata": {},
   "outputs": [],
   "source": [
    "kitchener.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "emotional-neutral",
   "metadata": {},
   "source": [
    "## Example: Calculating On-Time Performance\n",
    "As an example, let's calculate the on-time performance across all trains at all stations along the Kitchener corridor. We will define on-time performance as departing between 1 minute early and 5 minutes late (*Note: this is not how VIA defines their on-time performance*). We'll do this with the following steps:\n",
    "  1. Create a subset of data with only on-time departures\n",
    "  2. Group all departures by station name and train number\n",
    "  3. Group on-time departures by station name and train number\n",
    "  4. Merge the two datasets together\n",
    "  5. Calculate the on-time performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "variable-membership",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "grand-romance",
   "metadata": {},
   "source": [
    "## Saving Files\n",
    "Saving dataframes back into CSV files is quick and easy. We'll save our on-time performance data as well as our cleaned Kitchener data for later visualization use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tight-palace",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
